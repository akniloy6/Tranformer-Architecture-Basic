{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers from scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as f\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Self Attention Function***\n",
    "\n",
    "This is the function of a single attention head. This takes in three tensors named Q(query), K(key) & V(value). These are learnable parameters. The shapes of these tensors are (batch size, sequence_length, num_features/dimension of feature vector). These are generated using a feed forward layer which uses the embeddings embedded with positional encoding as input.\n",
    "\n",
    "Attention(Q,K,V) = softmax $(QK^T/\\sqrt d_k)V$\n",
    "\n",
    "Masking is added in the original paper, \n",
    "\n",
    "Attention(Q,K,V) = softmax $(QK^T/ \\sqrt d_k + M)V$. M is coded using a triangular function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BzhKcJJxv974OxWOVqUuQQ.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BzhKcJJxv974OxWOVqUuQQ.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_attention(Q: Tensor, K:Tensor, V: Tensor) -> Tensor:\n",
    "    qk = Q.bmm(K.transpose(1,2)) #matrix batchwise multiplication\n",
    "    scalling = Q.size(-1)**.5 #scalled by the square root of the number of features\n",
    "    softmax = f.softmax(qk/scalling,dim= -1) #conversion into softmax probability. values will be 0-1 via this.\n",
    "    self_attention_block = softmax.bmm(V) #MatMul again\n",
    "    return self_attention_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 50, 64])\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "q = Tensor(30,50,64)\n",
    "k = Tensor(30,50,64)\n",
    "v = Tensor(30,50,64)\n",
    "result = self_attention(q,k,v)\n",
    "print(result.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Multi-head Attention Class***\n",
    "\n",
    "This takes in three tensors named Q(query), K(key) & V(value). These are then passed through a linear layer and then self_attention is computed paralelly. That is why they are called multi-head attention. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, number_of_heads, model_dimension):\n",
    "        super().__init__()\n",
    "        self.q_l = nn.Linear(model_dimension,model_dimension)\n",
    "        self.k_l = nn.Linear(model_dimension,model_dimension)\n",
    "        self.v_l = nn.Linear(model_dimension,model_dimension)\n",
    "        \n",
    "    def forward(self, q,k,v):\n",
    "        q = self.q_l(q)\n",
    "        k = self.k_l(k)\n",
    "        v = self.v_l(v)\n",
    "        single_attention_head = self_attention(q,k,v)\n",
    "        return single_attention_head,v.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch size= 30 (passing 30 sentences at once, max number of words in each sentence= 50, 64 is the vector\n",
    "#represetation for each word, model dimension D_l\n",
    "q = Tensor(30,50,512)\n",
    "k = Tensor(30,50,512)\n",
    "v = Tensor(30,50,512)\n",
    "model = SelfAttention(8,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelfAttention(\n",
       "  (q_l): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (k_l): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (v_l): Linear(in_features=512, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention, v = model.forward(q,k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 50, 512])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
